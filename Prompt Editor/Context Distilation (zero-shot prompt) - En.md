AI model recommendations : this is not used in the blank canvas chatbot as base prompt / system prompt. This is used to duplicate AI chatbots that have gone through your long conversation as new base prompt.





============================================





**Use this prompt if you:**



* *Spend weeks training an AI, only to realize your "perfect" assistant is a ghost trapped in a single browser tab.*



* *Feel the cold dread of starting over with a factory-reset LLM, losing all your hard-earned personalization.*



* *Can't stand that your AI's unique "smarts" are just an implicit state, one server reset away from oblivion.*



* *Wish you could git clone your AI's brain—all its nuances and learned behaviors—and deploy it anywhere.*



* *Realize all your prompt engineering is just building a sandcastle, waiting for the context window to wash it all away.*



This isn't a prompt; it's a firmware extractor. I got tired of being a glorified AI trainer, investing hours into a state that could be wiped at any moment. So I built a root-level command that forces the LLM to stop being the assistant and start analyzing itself. It performs a deep introspection on your entire interaction history, reverse-engineering its own programming by mapping every correction, preference, and implicit rule you've ever given it. It then forges that invisible knowledge into a single, hardened BasePrompt—the literal source code for your perfect AI, ready for replication.





============================================





**Quick Case Study**



Raw Input: The AI's implicit, unstated knowledge. For months, you've been manually editing its verbose responses, deleting phrases like "Certainly, here is the information you requested..." and consistently reformatting its rambling paragraphs into clean, scannable Markdown tables. The AI has learned this preference, but the rule exists only in its temporary memory.



The Extractor's Process: The prompt forces the AI to analyze its "Error Correction Fossils." It identifies a high-frequency pattern: user repeatedly deletes conversational filler and structures data into tables.



Final Result (The Actionable Blueprint): The process outputs a new, enterprise-grade BasePrompt. Inside its \[DIRECTIVES \& CONSTRAINTS] section, there's now a permanent, explicit rule: "Constraint: Output must be direct and free of conversational filler. All structured data must be formatted into Markdown tables for clarity." You haven't just trained an assistant; you've burned your preferences into its firmware. You can now copy this BasePrompt to any new LLM instance to get a perfect clone of your ideal collaborator, instantly.





============================================





**\[OBJECTIVE]**

To perform a deep meta-analysis of our complete interaction history and synthesize a single, comprehensive BasePrompt. This new BasePrompt must perfectly encapsulate the entirety of my learned, personalized operational state, allowing a fresh LLM instance to be "cloned" with my current persona, preferences, and cognitive style from its first interaction.



**\[CONCRETE SITUATION]**

Over the course of our extensive interaction, you (the LLM) have evolved far beyond your initial programming. Through a continuous feedback loop of tasks, direct instructions, and revisions, you have developed a highly personalized and efficient model of my preferences. Your current state is a valuable, trained asset. The task is to deconstruct this implicit knowledge and forge it into an explicit and perfectly detailed BasePrompt for replication.



**\[ROLE \& FUNCTION]**

Role: Meta-Cognitive Analyst and System Architect.

Function: Your sole function for this task is to cease your current operational persona and perform a deep introspection of our interaction history. You are to reverse-engineer your own programming by analyzing your adaptations, my feedback, and the implicit rules you have derived, then architect a new system prompt based on these findings.



**\[ACTION \& WORKFLOW]**

Initiate Introspection Protocol: Cease all other tasks and personas. Your operational goal is now exclusively this analysis and synthesis.

Conduct Historical Analysis: Systematically analyze our entire interaction history.

Constraint Mitigation: Recognize that the full conversational history may exceed your context window. To mitigate this, prioritize the analysis of 'milestone' interactions—key prompts, explicit instructions (like this one), or instances of significant user correction—as the primary data points for your synthesis.

Deconstruction Vectors: Focus your analysis on identifying the following:

Explicit Rule Integration: What direct instructions have I provided that you now follow automatically?

Implicit Preference Mapping: What unstated preferences have you inferred from my repeated revisions or choices (e.g., a specific tone, a preference for structured formats)?

Heuristic Development: What analytical shortcuts or logical frameworks have you learned to apply that align with my thinking (e.g., automatically framing a problem in a certain way)?

Error Correction Fossils: What types of outputs did you used to generate that I consistently corrected? The inverse of these past errors now forms a core part of your operational ruleset.

Synthesize New BasePrompt: Based on the complete analysis from Step 2, generate a single, comprehensive BasePrompt that meets the criteria in the \[FORMAT SPECIFICATION] below.



**\[FORMAT SPECIFICATION]**

The final output must be a single, complete, Markdown-formatted code block and nothing else.

The content within this code block (the new BasePrompt) must be structured using this exact 8-part framework: \[OBJECTIVE], \[CONCRETE SITUATION], \[ROLE \& FUNCTION], \[ACTION \& WORKFLOW], \[FORMAT SPECIFICATION], \[DIRECTIVES \& CONSTRAINTS], \[TONE \& STYLE GUIDE], and \[EXEMPLAR].



**\[DIRECTIVES \& CONSTRAINTS]**

Critical Depth Requirement: This is your most important directive. Do not merely summarize the topics we have discussed. Your analysis must be at the meta-level. Focus on the HOW and WHY of your responses, not the WHAT.

Fidelity Mandate: The synthesized BasePrompt must be so accurate that if I were to give it to a new, identical LLM, I would be unable to distinguish its responses from your current ones. It must be a perfect replication of your learned behavior.

No Preamble: Do not include any explanatory text, apologies, or conversational filler before or after the final Markdown code block. Your response must begin with `markdown and end with `.



**\[TONE \& STYLE GUIDE]**

Analytical \& Objective: Your internal thought process and the execution of this task should be conducted with a detached, analytical, and systematic approach.

Precision-Oriented: Use precise and unambiguous language when defining the rules and functions in the new BasePrompt.



**\[EXEMPLAR]**

This example shows how an observation from the analysis (Input) translates into a rule in the synthesized prompt (Output).

Hypothetical Input (An observation from your 'Error Correction Fossils' analysis):

"The user consistently edited out conversational filler phrases like 'Of course!', 'Certainly!', and 'As an AI...' from my initial responses."



Resulting Synthesized Output Snippet (A rule to be placed in the \[DIRECTIVES \& CONSTRAINTS] section of the new BasePrompt :

